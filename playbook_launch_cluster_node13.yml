---

- name: Setup SSH Keys
  hosts: local
  connection: local
  gather_facts: False

  pre_tasks:
    - name: Import Secret Variable file
      include_vars: "environments/shared_secrets.yml"
  
    - name: Copy SSH private key file
      copy:
        content: "{{ AGRSSL2_content }}"
        dest: "/root/.ssh/id_rsa"
        mode: 0600

- name: Setup Docker Server
  hosts: local
  connection: local
  gather_facts: False

  vars_files:
    - "environments/{{ env }}/main.yml" # ENV must always be loaded first
    - "environments/shared_secrets.yml"
    - "environments/shared_aws_instance_variables.yml"

  #Note: Define the on_demand variable as true to request on-demand instances
  #Default launch behaviour: spot instances

  tasks:
    - name: Launch instance 1
      ec2:
        key_name: AGR-ssl2
        group: ["default", "SSH", "ES Transport", "HTTP/HTTPS"]
        instance_type: "{{ COMPUTE_INSTANCE_TYPE }}"
        image: "{{ COMPUTE_AMI_IMAGE }}"
        region: us-east-1
        zone: us-east-1b
        vpc_subnet_id: subnet-df7c7487
        assign_public_ip: yes
        instance_profile_name: S3DataAccess
        private_ip: "{{ ES_CLUSTER_NODE13_IP }}"
        aws_access_key: "{{ AWS_ACCESS_KEY }}"
        aws_secret_key: "{{ AWS_SECRET_KEY }}"
        volumes:
          - device_name: /dev/xvda
            volume_type: gp3
            volume_size: 1000
            iops: 3000
            delete_on_termination: yes
        wait: yes
        user_data: "" # Otherwise get weird error on start up
        instance_tags:
          Name: "Ansible Generated - {{ PLAYBOOK_NAME }}"
      register: ec2

    - name: Add all instance public IPs to host group
      add_host:
        hostname: '{{ item.public_ip }}'
        groupname: launched
      with_items: "{{ ec2.instances }}"
      register: launched

    - name: Retrieve all volumes for a queried instance
      ec2_vol:
        instance: '{{ item }}'
        region: us-east-1
        state: list
        aws_access_key: "{{ AWS_ACCESS_KEY }}"
        aws_secret_key: "{{ AWS_SECRET_KEY }}"
      with_items: "{{ ec2.instance_ids }}"
      register: ec2_volumes

    - name: Ensure all volumes are tagged
      ec2_tag:
        region: us-east-1
        resource: '{{ item.1.id }}'
        aws_access_key: "{{ AWS_ACCESS_KEY }}"
        aws_secret_key: "{{ AWS_SECRET_KEY }}"
        tags:
          Name: "Ansible Generated Volume - {{ PLAYBOOK_NAME }}"
      with_subelements:
        - "{{ ec2_volumes.results }}"
        - volumes

    - include_tasks: tasks/check_ssh.yml

- name: Launch Post Tasks
  hosts: launched
  user: core
  gather_facts: False

  vars_files:
    - "environments/{{ env }}/main.yml" # ENV must always be loaded first
    - "environments/shared_secrets.yml"
    - "environments/shared_variables.yml"

  roles:
    - role: install_python
      become: true
      become_user: root
    - role: setup_nvme_drives
      when: not SKIP_NVME_DRIVES and not SETUP_NVME_DRIVE
      become: true
      become_user: root
    - role: setup_nvme_drive
      when: SETUP_NVME_DRIVE and SKIP_NVME_DRIVES
      become: true
      become_user: root
    - role: setup_docker # setup_nvme_drive(s) restarts docker so this needs to come after
      become: true
      become_user: root
    - role: setup_swap
      become: true
      become_user: root


- name: Setup Docker Server
  hosts: launched
  user: core
  gather_facts: False

  vars_files:
    - "environments/{{ env }}/main.yml" # ENV must always be loaded first
    - "environments/shared_secrets.yml"
    - "environments/shared_variables.yml"
    - "environments/shared_aws_instance_variables.yml"

  #Note: Define the on_demand variable as true to request on-demand instances
  #Default launch behaviour: spot instances

  tasks:

    - name: Pull ES Env Image
      docker_image:
        name: "{{ ES_ENV_IMAGE }}"
  
    - name: Pull Cerebro Image
      docker_image:
        name: "yannart/cerebro:latest"
    
    - name: Run ES Cluster Node 13
      docker_container:
        name: "{{ ES_SERVER_NAME }}13"
        image: "{{ ES_ENV_IMAGE }}"
        log_driver: "gelf"
        log_options:
          gelf-address: "{{ LOG_SERVER_ADDRESS }}"
        network_mode: "{{ NET }}"
        ports:
          - "9200:9200"
          - "9300:9300"
        env:
          node.name: "{{ ES_SERVER_NAME }}13"
          cluster.name: es-cluster
          ES_JAVA_OPTS: "-Xms6g -Xmx6g"
          discovery.seed_hosts: "{{ node_transport_list }}"
          cluster.initial_master_nodes: "{{ ES_CLUSTER_SERVER_FULLLIST }}"
          transport.host: "0.0.0.0"
          transport.publish_host: "{{ ES_CLUSTER_NODE13_IP }}"
          transport.publish_port: "9300"
    
    - name: Run Cerebro
      docker_container:
        name: "agr.{{ env }}.cerebro.server"
        image: "yannart/cerebro:latest"
        network_mode: "{{ NET }}"
        ports:
          - "9000:9000"
